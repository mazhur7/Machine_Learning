{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of multiple_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xtogwoEGwL8"
      },
      "source": [
        "###  lifelike business challenge: Fifty startups is going to be analyzed a venture capitalist fund\r\n",
        "We've got datafile *50_Startup.csv* with 50 companies year reports in total here. \r\n",
        "Startups have some extracts from their profit and loss statements from their income report.\r\n",
        "The simple questins is:\r\n",
        "*    how much did the company in that year spend on research and development,  how much did it spend on an administration. And how was it spent on marketing.\r\n",
        "*   What was the profit of that company for that financial year.\r\n",
        "\r\n",
        "But the venture capitalist  would like to have more detailed analytics to  undeestand companies perform better:\r\n",
        "\r\n",
        "*  In which region companies perform better?\r\n",
        "*  Are we looking for companies to spend more on R&D or on research and development or  on marketing?\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX_WF2hRTFmM"
      },
      "source": [
        "##Assumptions of a Linear Regression\r\n",
        "1. Linearity\r\n",
        "2. Homoscedasticity\r\n",
        "3. Multivariate normality\r\n",
        "4. Independence of errors\r\n",
        "5. Lack of multicollinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_YHJjnD_Tja"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrxyEKGn_ez7"
      },
      "source": [
        "dataset = pd.read_csv('50_Startups.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "Y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCFwZVigqehO"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [3])], remainder='passthrough')\r\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td1haOQj0LDI"
      },
      "source": [
        "# for BE model: Avoiding the Dummy Variable Trap\r\n",
        "X = X[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PaRQWVTqF5P"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7pad5E5u4uS",
        "outputId": "0c9b8d7d-af24-46ef-9ac9-d0e8c18c494c"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\r\n",
        "regressor = LinearRegression()\r\n",
        "regressor.fit(X_train, Y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37h0TjYNvsep",
        "outputId": "9f18833a-7b0c-4e45-e227-12471760b150"
      },
      "source": [
        "y_pred = regressor.predict(X_test)\r\n",
        "np.set_printoptions(precision=2)\r\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),Y_test.reshape(len(Y_test),1)),1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[103015.2  103282.38]\n",
            " [132582.28 144259.4 ]\n",
            " [132447.74 146121.95]\n",
            " [ 71976.1   77798.83]\n",
            " [178537.48 191050.39]\n",
            " [116161.24 105008.31]\n",
            " [ 67851.69  81229.06]\n",
            " [ 98791.73  97483.56]\n",
            " [113969.44 110352.25]\n",
            " [167921.07 166187.94]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBenSsKDzfs8"
      },
      "source": [
        "# for BE model -  Building the optimal model using Backward Elimination\r\n",
        "import statsmodels.api as sm\r\n",
        "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\r\n",
        "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\r\n",
        "X_opt = X_opt.astype(np.float64)\r\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n",
        "regressor_OLS.summary()X_opt = X[:, [0, 1, 3, 4, 5]]\r\n",
        "X_opt = X_opt.astype(np.float64)\r\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n",
        "regressor_OLS.summary()X_opt = X[:, [0, 3, 4, 5]]\r\n",
        "X_opt = X_opt.astype(np.float64)\r\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n",
        "regressor_OLS.summary()X_opt = X[:, [0, 3, 5]]\r\n",
        "X_opt = X_opt.astype(np.float64)\r\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n",
        "regressor_OLS.summary()X_opt = X[:, [0, 3]]\r\n",
        "X_opt = X_opt.astype(np.float64)regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n",
        "regressor_OLS.summary()\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}